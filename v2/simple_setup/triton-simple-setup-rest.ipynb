{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying NVIDIA Triton Inference Server in AI Platform Prediction Custom Container (REST API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk through the process of deploying NVIDIA's Triton Inference Server into AI Platform Prediction Custom Container service in the Direct Model Server mode:\n",
    "\n",
    "![](img/caip_triton_container_diagram_direct.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='[Enter project name - REQUIRED]'\n",
    "REPOSITORY='caipcustom'\n",
    "REGION='us-central1'\n",
    "TRITON_VERSION='20.06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "\n",
    "MODEL_BUCKET='gs://{}-{}'.format(PROJECT_ID,random.randint(10000,99999))\n",
    "ENDPOINT='https://{}-ml.googleapis.com/v1'.format(REGION)\n",
    "TRITON_IMAGE='tritonserver:{}-py3'.format(TRITON_VERSION)\n",
    "CAIP_IMAGE='{}-docker.pkg.dev/{}/{}/{}'.format(REGION,PROJECT_ID,REPOSITORY,TRITON_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='tsaikevin-1238'\n",
    "REPOSITORY='caipcustom'\n",
    "REGION='us-central1'\n",
    "TRITON_VERSION='20.06'\n",
    "\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "\n",
    "MODEL_BUCKET='gs://{}-{}'.format(PROJECT_ID,random.randint(10000,99999))\n",
    "ENDPOINT='https://{}-ml.googleapis.com/v1'.format(REGION)\n",
    "TRITON_IMAGE='tritonserver:{}-py3'.format(TRITON_VERSION)\n",
    "CAIP_IMAGE='{}-docker.pkg.dev/{}/{}/{}'.format(REGION,PROJECT_ID,REPOSITORY,TRITON_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BUCKET='gs://tsaikevin-1238-80838'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://tsaikevin-1238-80838\n",
      "https://us-central1-ml.googleapis.com/v1\n",
      "tritonserver:20.06-py3\n",
      "us-central1-docker.pkg.dev/tsaikevin-1238/caipcustom/tritonserver:20.06-py3\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_BUCKET)\n",
    "print(ENDPOINT)\n",
    "print(TRITON_IMAGE)\n",
    "print(CAIP_IMAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT_ID\"]=PROJECT_ID\n",
    "os.environ[\"MODEL_BUCKET\"]=MODEL_BUCKET\n",
    "os.environ[\"ENDPOINT\"]=ENDPOINT\n",
    "os.environ[\"CAIP_IMAGE\"]=CAIP_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Artifact Registry\n",
    "This will be used to store the container image for the model server Triton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta artifacts repositories create $REPOSITORY --repository-format=docker --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the container\n",
    "We will make a copy of the Triton container image into the Artifact Registry, where AI Platform Custom Container Prediction will only pull from during Model Version setup. The following steps will download the NVIDIA Triton Inference Server container to your VM, then upload it to your repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.06-py3: Pulling from nvidia/tritonserver\n",
      "Digest: sha256:36f94c39221c4e19921d44296690991057bbebbb15f59dacd88e25ff331bd307\n",
      "Status: Image is up to date for nvcr.io/nvidia/tritonserver:20.06-py3\n",
      "nvcr.io/nvidia/tritonserver:20.06-py3\n",
      "The push refers to repository [us-central1-docker.pkg.dev/tsaikevin-1238/caipcustom/tritonserver]\n",
      "\n",
      "\u001b[1B7aefd4ea: Preparing \n",
      "\u001b[1Bab22f50a: Preparing \n",
      "\u001b[1B4bb8a14c: Preparing \n",
      "\u001b[1Bc357696a: Preparing \n",
      "\u001b[1B35b111ce: Preparing \n",
      "\u001b[1B422b8a56: Preparing \n",
      "\u001b[1B5c73ed66: Preparing \n",
      "\u001b[1B91761c8c: Preparing \n",
      "\u001b[1Bdcbd0b8f: Preparing \n",
      "\u001b[1B3fad0b37: Preparing \n",
      "\u001b[1Bbca7086a: Preparing \n",
      "\u001b[1Ba1fe0dac: Preparing \n",
      "\u001b[1B16262158: Preparing \n",
      "\u001b[1Bfaf9c798: Preparing \n",
      "\u001b[1B4dd7a77b: Preparing \n",
      "\u001b[1B4f618f62: Preparing \n",
      "\u001b[1B114ab5c3: Preparing \n",
      "\u001b[1Bb7588393: Preparing \n",
      "\u001b[1B7a4b3a0b: Preparing \n",
      "\u001b[1B3708beeb: Preparing \n",
      "\u001b[1Bc2e3c7b1: Preparing \n",
      "\u001b[1B43d8d50a: Preparing \n",
      "\u001b[1B9bd9798f: Preparing \n",
      "\u001b[1B27c9414b: Preparing \n",
      "\u001b[1B4c1700eb: Preparing \n",
      "\u001b[1B46c23e3a: Preparing \n",
      "\u001b[1Bb877a610: Preparing \n",
      "\u001b[1Be28a7437: Preparing \n",
      "\u001b[1Bd0584a68: Preparing \n",
      "\u001b[1Bcd722629: Preparing \n",
      "\u001b[1B7d6d8dba: Preparing \n",
      "\u001b[1Bf0c094ce: Preparing \n",
      "\u001b[1B579ef21b: Preparing \n",
      "\u001b[1Bd3acfe42: Preparing \n",
      "\u001b[1B29219aba: Preparing \n",
      "\u001b[1Be3bdea67: Preparing \n",
      "\u001b[1B7458d04b: Preparing \n",
      "\u001b[1B37a24627: Preparing \n",
      "\u001b[1Bef4a95c3: Preparing \n",
      "\u001b[3B37a24627: Layer already exists \u001b[35A\u001b[2K\u001b[29A\u001b[2K\u001b[21A\u001b[2K\u001b[15A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K20.06-py3: digest: sha256:36f94c39221c4e19921d44296690991057bbebbb15f59dacd88e25ff331bd307 size: 8683\n"
     ]
    }
   ],
   "source": [
    "!docker pull nvcr.io/nvidia/$TRITON_IMAGE && \\\n",
    " docker tag nvcr.io/nvidia/$TRITON_IMAGE $CAIP_IMAGE && \\\n",
    " docker push $CAIP_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the NVIDIA Triton Inference Server repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'triton-inference-server'...\n",
      "remote: Enumerating objects: 285, done.\u001b[K\n",
      "remote: Counting objects: 100% (285/285), done.\u001b[K\n",
      "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
      "remote: Total 25484 (delta 149), reused 161 (delta 89), pack-reused 25199\u001b[K\n",
      "Receiving objects: 100% (25484/25484), 14.34 MiB | 23.99 MiB/s, done.\n",
      "Resolving deltas: 100% (18800/18800), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/triton-inference-server.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the GCS bucket where the model artifacts will be copied to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://tsaikevin-1238-80838/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb $MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage model artifacts and copy to bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R triton-inference-server/docs/examples/model_repository/* model_repository/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd triton-inference-server\n",
      "error: pathspec 'r20.06' did not match any file(s) known to git.\n"
     ]
    }
   ],
   "source": [
    "# !echo cd triton-inference-server && git checkout r$TRITON_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/caip-triton/v2/simple_setup/triton-inference-server\n",
      "Branch r20.06 set up to track remote branch r20.06 from origin.\n",
      "Switched to a new branch 'r20.06'\n",
      "/home/jupyter/caip-triton/v2/simple_setup\n",
      "total 88\n",
      "-rw-r--r--  1 jupyter jupyter 13652 Oct 19 08:48 get_request_body_simple.py\n",
      "drwxr-xr-x  2 jupyter jupyter  4096 Oct 19 08:48 \u001b[0m\u001b[01;34mimg\u001b[0m/\n",
      "drwxr-xr-x  6 jupyter jupyter  4096 Oct 26 07:24 \u001b[01;34mmodel_repository\u001b[0m/\n",
      "-rw-r--r--  1 jupyter jupyter  1605 Oct 22 18:27 README.md\n",
      "drwxr-xr-x 10 jupyter jupyter  4096 Oct 26 07:24 \u001b[01;34mtriton-inference-server\u001b[0m/\n",
      "-rw-r--r--  1 jupyter jupyter 34769 Oct 26 07:23 triton-simple-setup-rest.ipynb\n",
      "-rw-r--r--  1 jupyter jupyter 20384 Oct 26 07:07 triton-simple-setup-sdk.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd triton-inference-server\n",
    "!git checkout r$TRITON_VERSION\n",
    "%cd ..\n",
    "%ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ mkdir -p model_repository/resnet50_netdef/1\n",
      "+ wget -O model_repository/resnet50_netdef/1/model.netdef http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/predict_net.pb\n",
      "--2020-10-26 07:25:15--  http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/predict_net.pb\n",
      "Resolving download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)... 52.216.147.11\n",
      "Connecting to download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)|52.216.147.11|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31649 (31K) [binary/octet-stream]\n",
      "Saving to: ‘model_repository/resnet50_netdef/1/model.netdef’\n",
      "\n",
      "model_repository/re 100%[===================>]  30.91K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2020-10-26 07:25:15 (1.05 MB/s) - ‘model_repository/resnet50_netdef/1/model.netdef’ saved [31649/31649]\n",
      "\n",
      "+ wget -O model_repository/resnet50_netdef/1/init_model.netdef http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/init_net.pb\n",
      "--2020-10-26 07:25:15--  http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/init_net.pb\n",
      "Resolving download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)... 52.216.147.11\n",
      "Connecting to download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)|52.216.147.11|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 128070759 (122M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘model_repository/resnet50_netdef/1/init_model.netdef’\n",
      "\n",
      "model_repository/re 100%[===================>] 122.14M  85.4MB/s    in 1.4s    \n",
      "\n",
      "2020-10-26 07:25:16 (85.4 MB/s) - ‘model_repository/resnet50_netdef/1/init_model.netdef’ saved [128070759/128070759]\n",
      "\n",
      "+ mkdir -p model_repository/inception_graphdef/1\n",
      "+ wget -O /tmp/inception_v3_2016_08_28_frozen.pb.tar.gz https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\n",
      "--2020-10-26 07:25:17--  https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.191.128, 172.217.212.128, 172.217.214.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.191.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88668554 (85M) [application/gzip]\n",
      "Saving to: ‘/tmp/inception_v3_2016_08_28_frozen.pb.tar.gz’\n",
      "\n",
      "/tmp/inception_v3_2 100%[===================>]  84.56M   165MB/s    in 0.5s    \n",
      "\n",
      "2020-10-26 07:25:17 (165 MB/s) - ‘/tmp/inception_v3_2016_08_28_frozen.pb.tar.gz’ saved [88668554/88668554]\n",
      "\n",
      "+ cd /tmp\n",
      "+ tar xzf inception_v3_2016_08_28_frozen.pb.tar.gz\n",
      "+ mv /tmp/inception_v3_2016_08_28_frozen.pb model_repository/inception_graphdef/1/model.graphdef\n",
      "+ mkdir -p model_repository/densenet_onnx/1\n",
      "+ wget -O model_repository/densenet_onnx/1/model.onnx https://contentmamluswest001.blob.core.windows.net/content/14b2744cf8d6418c87ffddc3f3127242/9502630827244d60a1214f250e3bbca7/08aed7327d694b8dbaee2c97b8d0fcba/densenet121-1.2.onnx\n",
      "--2020-10-26 07:25:19--  https://contentmamluswest001.blob.core.windows.net/content/14b2744cf8d6418c87ffddc3f3127242/9502630827244d60a1214f250e3bbca7/08aed7327d694b8dbaee2c97b8d0fcba/densenet121-1.2.onnx\n",
      "Resolving contentmamluswest001.blob.core.windows.net (contentmamluswest001.blob.core.windows.net)... 13.88.144.240\n",
      "Connecting to contentmamluswest001.blob.core.windows.net (contentmamluswest001.blob.core.windows.net)|13.88.144.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 32719461 (31M) [application/octet-stream]\n",
      "Saving to: ‘model_repository/densenet_onnx/1/model.onnx’\n",
      "\n",
      "model_repository/de 100%[===================>]  31.20M  16.7MB/s    in 1.9s    \n",
      "\n",
      "2020-10-26 07:25:21 (16.7 MB/s) - ‘model_repository/densenet_onnx/1/model.onnx’ saved [32719461/32719461]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./triton-inference-server/docs/examples/fetch_models.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model_repository/simple/config.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/simple/1/model.graphdef [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/inception_graphdef/inception_labels.txt [Content-Type=text/plain]...\n",
      "Copying file://model_repository/inception_graphdef/1/model.graphdef [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/resnet50_netdef/1/init_model.netdef [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/resnet50_netdef/1/model.netdef [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/inception_graphdef/config.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/densenet_onnx/config.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/densenet_onnx/densenet_labels.txt [Content-Type=text/plain]...\n",
      "Copying file://model_repository/densenet_onnx/1/model.onnx [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/simple_string/config.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file://model_repository/simple_string/1/model.graphdef [Content-Type=application/octet-stream]...\n",
      "| [12/12 files][244.7 MiB/244.7 MiB] 100% Done                                  \n",
      "Operation completed over 12 objects/244.7 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -R model_repository/ $MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://tsaikevin-1238-80838/model_repository/densenet_onnx/\n",
      "gs://tsaikevin-1238-80838/model_repository/inception_graphdef/\n",
      "gs://tsaikevin-1238-80838/model_repository/resnet50_netdef/\n",
      "gs://tsaikevin-1238-80838/model_repository/simple/\n",
      "gs://tsaikevin-1238-80838/model_repository/simple_string/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $MODEL_BUCKET/model_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare request payload\n",
    "\n",
    "To prepare the payload format, we have included a utility get_request_body_simple.py.  To use this utility, install the following library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geventhttpclient in /opt/conda/lib/python3.7/site-packages (1.4.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from geventhttpclient) (1.15.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from geventhttpclient) (2020.6.20)\n",
      "Requirement already satisfied: gevent>=0.13 in /opt/conda/lib/python3.7/site-packages (from geventhttpclient) (20.6.2)\n",
      "Requirement already satisfied: zope.event in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (4.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (50.3.0)\n",
      "Requirement already satisfied: zope.interface in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (5.1.0)\n",
      "Requirement already satisfied: greenlet>=0.4.16; platform_python_implementation == \"CPython\" in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (0.4.16)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install geventhttpclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare non-binary request payload\n",
    "\n",
    "The first model will illustrate a non-binary payload.  The following command will create a KF Serving v2 format non-binary payload to be used with the \"simple\" model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 get_request_body_simple.py -m simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare binary request payload\n",
    "\n",
    "Triton's implementation of KF Serving v2 protocol for binary data appends the binary data after the json body.  Triton requires an additional header for offset:\n",
    "\n",
    "`Inference-Header-Content-Length: [offset]`\n",
    "\n",
    "We have provided a script that will automatically resize the image to the proper size for ResNet-50 [224, 224, 3] and calculate the proper offset.  The following command takes an image file and outputs the necessary data structure to be use with the \"resnet50_netdef\" model.  Please note down this offset as it will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n",
      "Add Header: Inference-Header-Content-Length: 138\n"
     ]
    }
   ],
   "source": [
    "!python3 get_request_body_simple.py -m image -f triton-inference-server/qa/images/mug.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and deploy Model and Model Version\n",
    "\n",
    "In this section, we will deploy two models:\n",
    "1. Simple model with non-binary data.  KF Serving v2 protocol specifies a json format with non-binary data in the json body itself.\n",
    "2. Binary data model with ResNet-50.  Triton's implementation of binary data for KF Server v2 protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple model (non-binary data)\n",
    "\n",
    "#### Create Model\n",
    "\n",
    "AI Platform Prediction uses a Model/Model Version Hierarchy, where the Model is a logical grouping of Model Versions.  We will first create the Model.\n",
    "\n",
    "Because the MODEL_NAME variable will be used later to specify the predict route, and Triton will use that route to run prediction on a specific model, we must set the value of this variable to a valid name of a model.  For this section, will use the \"simple\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=simple\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME=simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 172.253.114.95:443...\n",
      "* Connected to us-central1-ml.googleapis.com (172.253.114.95) port 443 (#0)\n",
      "* ALPN, offering h2\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use h2\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Oct  6 06:40:00 2020 GMT\n",
      "*  expire date: Dec 29 06:40:00 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "* Using HTTP2, server supports multi-use\n",
      "* Connection state changed (HTTP/2 confirmed)\n",
      "* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n",
      "* Using Stream ID: 1 (easy handle 0x55bb07c21da0)\n",
      "> POST /v1/projects/tsaikevin-1238/models/ HTTP/2\n",
      "> Host: us-central1-ml.googleapis.com\n",
      "> user-agent: curl/7.71.1\n",
      "> accept: */*\n",
      "> content-type: application/json\n",
      "> authorization: Bearer ya29.a0AfH6SMC9FqpTEsjws26ZkhPbwtc55VhVpbJLNO8CHb3wPxFzYNIO7tLB_QvHNWUU_IjXCw5mq0jGXTXje9W0gcnTe_lzowIuAmdKe_sk8FR2WJcR83VI8Jq37OjLuBlCbgNuvzE3F0_B94lJlgO4DVGyEvGAIu02cgsuXjG6pC2h\n",
      "> content-length: 18\n",
      "> \n",
      "* Connection state changed (MAX_CONCURRENT_STREAMS == 100)!\n",
      "* We are completely uploaded and fine\n",
      "< HTTP/2 200 \n",
      "< content-type: application/json; charset=UTF-8\n",
      "< vary: X-Origin\n",
      "< vary: Referer\n",
      "< vary: Origin,Accept-Encoding\n",
      "< date: Mon, 26 Oct 2020 08:06:25 GMT\n",
      "< server: ESF\n",
      "< cache-control: private\n",
      "< x-xss-protection: 0\n",
      "< x-frame-options: SAMEORIGIN\n",
      "< x-content-type-options: nosniff\n",
      "< accept-ranges: none\n",
      "< \n",
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/models/simple\",\n",
      "  \"regions\": [\n",
      "    \"us-central1\"\n",
      "  ],\n",
      "  \"etag\": \"3Z5ibof88CU=\"\n",
      "}\n",
      "* Connection #0 to host us-central1-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -X \\\n",
    "    POST -v -k -H \"Content-Type: application/json\" \\\n",
    "    -d \"{'name': '\"$MODEL_NAME\"'}\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Version\n",
    "\n",
    "After the Model is created, we can now create a Model Version under this Model.  Each Model Version will need a name that is unique within the Model.  In AI Platform Prediction Custom Container, a {Project}/{Model}/{ModelVersion} uniquely identifies the specific container and model artifact used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VERSION_NAME=v01\n"
     ]
    }
   ],
   "source": [
    "%env VERSION_NAME=v01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following specifications tell AI Platform how to create the Model Version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "triton_simple_version = {\n",
    "  \"name\": os.getenv(\"VERSION_NAME\"),\n",
    "  \"deployment_uri\": os.getenv(\"MODEL_BUCKET\")+\"/model_repository\",\n",
    "  \"container\": {\n",
    "    \"image\": os.getenv(\"CAIP_IMAGE\"),\n",
    "    \"args\": [\"tritonserver\",\n",
    "             \"--model-repository=$(AIP_STORAGE_URI)\"\n",
    "    ],\n",
    "    \"env\": [\n",
    "    ], \n",
    "    \"ports\": [\n",
    "      { \"containerPort\": 8000 }\n",
    "    ]\n",
    "  },\n",
    "  \"routes\": {\n",
    "    \"predict\": \"/v2/models/\"+os.getenv(\"MODEL_NAME\")+\"/infer\",\n",
    "    \"health\": \"/v2/models/\"+os.getenv(\"MODEL_NAME\")\n",
    "  },\n",
    "  \"machine_type\": \"n1-standard-4\",\n",
    "  \"acceleratorConfig\": {\n",
    "    \"count\":1,\n",
    "    \"type\":\"nvidia-tesla-t4\"\n",
    "  },\n",
    "  \"autoScaling\": {\n",
    "    \"minNodes\": 1\n",
    "  }\n",
    "}\n",
    "\n",
    "with open(\"triton_simple_version.json\", \"w\") as f: \n",
    "  json.dump(triton_simple_version, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 74.125.124.95:443...\n",
      "* Connected to us-central1-ml.googleapis.com (74.125.124.95) port 443 (#0)\n",
      "* ALPN, offering h2\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use h2\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Oct  6 06:40:00 2020 GMT\n",
      "*  expire date: Dec 29 06:40:00 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "* Using HTTP2, server supports multi-use\n",
      "* Connection state changed (HTTP/2 confirmed)\n",
      "* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n",
      "* Using Stream ID: 1 (easy handle 0x55d00f712570)\n",
      "> POST /v1/projects/tsaikevin-1238/models/simple/versions HTTP/2\n",
      "> Host: us-central1-ml.googleapis.com\n",
      "> user-agent: curl/7.71.1\n",
      "> accept: */*\n",
      "> content-type: application/json\n",
      "> authorization: Bearer ya29.a0AfH6SMCfJGAaxVQLlpiVJ8t6FSs4AWTJrWmh-RTZ0N1YqiF7nX8I5_FVBnZbBgBkt1Bnep8W_qaYyqfpBy-eJrLZewxZh5FFvLUyxXd2Tb4qnkTSIqV9sEx422irmfjPDY0qEL3h98iYR5oppuDff0rQhbp5uyVdoa5mEyd7wYZ9\n",
      "> content-length: 504\n",
      "> \n",
      "* Connection state changed (MAX_CONCURRENT_STREAMS == 100)!\n",
      "* We are completely uploaded and fine\n",
      "< HTTP/2 200 \n",
      "< content-type: application/json; charset=UTF-8\n",
      "< vary: X-Origin\n",
      "< vary: Referer\n",
      "< vary: Origin,Accept-Encoding\n",
      "< date: Mon, 26 Oct 2020 08:06:34 GMT\n",
      "< server: ESF\n",
      "< cache-control: private\n",
      "< x-xss-protection: 0\n",
      "< x-frame-options: SAMEORIGIN\n",
      "< x-content-type-options: nosniff\n",
      "< accept-ranges: none\n",
      "< \n",
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/operations/create_simple_v01-1603699593867\",\n",
      "  \"metadata\": {\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.ml.v1.OperationMetadata\",\n",
      "    \"createTime\": \"2020-10-26T08:06:34Z\",\n",
      "    \"operationType\": \"CREATE_VERSION\",\n",
      "    \"modelName\": \"projects/tsaikevin-1238/models/simple\",\n",
      "    \"version\": {\n",
      "      \"name\": \"projects/tsaikevin-1238/models/simple/versions/v01\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-1238-80838/model_repository\",\n",
      "      \"createTime\": \"2020-10-26T08:06:33Z\",\n",
      "      \"autoScaling\": {\n",
      "        \"minNodes\": 1\n",
      "      },\n",
      "      \"etag\": \"wjgau0OqJ7s=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"us-central1-docker.pkg.dev/tsaikevin-1238/caipcustom/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/simple/infer\",\n",
      "        \"health\": \"/v2/models/simple\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "* Connection #0 to host us-central1-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -X \\\n",
    "    POST -v -k -H \"Content-Type: application/json\" \\\n",
    "    -d @triton_simple_version.json \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of Model Version creation\n",
    "\n",
    "Creating a Model Version may take several minutes.  You can check on the status of this specfic Model Version with the following, and a successful deployment will show:\n",
    "\n",
    "`\"state\": \"READY\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/models/simple/versions/v01\",\n",
      "  \"deploymentUri\": \"gs://tsaikevin-1238-80838/model_repository\",\n",
      "  \"createTime\": \"2020-10-26T08:06:33Z\",\n",
      "  \"autoScaling\": {\n",
      "    \"minNodes\": 1\n",
      "  },\n",
      "  \"state\": \"FAILED\",\n",
      "  \"errorMessage\": \"Model server terminated: model server container terminated: exit_code: 1\\nreason: \\\"Error\\\"\\nstarted_at {\\n  seconds: 1603701184\\n}\\nfinished_at {\\n  seconds: 1603701195\\n}\\n\",\n",
      "  \"etag\": \"epzDdKe/dRw=\",\n",
      "  \"machineType\": \"n1-standard-4\",\n",
      "  \"acceleratorConfig\": {\n",
      "    \"count\": \"1\",\n",
      "    \"type\": \"NVIDIA_TESLA_T4\"\n",
      "  },\n",
      "  \"container\": {\n",
      "    \"image\": \"us-central1-docker.pkg.dev/tsaikevin-1238/caipcustom/tritonserver:20.06-py3\",\n",
      "    \"args\": [\n",
      "      \"tritonserver\",\n",
      "      \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "    ],\n",
      "    \"ports\": [\n",
      "      {\n",
      "        \"containerPort\": 8000\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"routes\": {\n",
      "    \"predict\": \"/v2/models/simple/infer\",\n",
      "    \"health\": \"/v2/models/simple\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/${VERSION_NAME}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To list all Model Versions and their states in this Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"versions\": [\n",
      "    {\n",
      "      \"name\": \"projects/tsaikevin-1238/models/simple/versions/v01\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-1238-80838/model_repository\",\n",
      "      \"createTime\": \"2020-10-26T07:26:01Z\",\n",
      "      \"autoScaling\": {\n",
      "        \"minNodes\": 1\n",
      "      },\n",
      "      \"state\": \"CREATING\",\n",
      "      \"etag\": \"gGWWjmXn/Os=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"us-central1-docker.pkg.dev/tsaikevin-1238/caipcustom/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/simple/infer\",\n",
      "        \"health\": \"/v2/models/simple\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run prediction using `curl`\n",
    "\n",
    "The \"simple\" model takes two tensors with shape [1,16] and does a couple of basic arithmetic operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"Field: name Error: Online prediction is unavailable for this version. Please verify that CreateVersion has completed successfully.\",\n",
      "    \"status\": \"NOT_FOUND\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\n",
      "        \"fieldViolations\": [\n",
      "          {\n",
      "            \"field\": \"name\",\n",
      "            \"description\": \"Online prediction is unavailable for this version. Please verify that CreateVersion has completed successfully.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST ${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/${VERSION_NAME}:predict \\\n",
    "    -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    -d '{ \\\n",
    "            \"id\": \"0\", \\\n",
    "            \"inputs\": [ \\\n",
    "                { \\\n",
    "                    \"name\": \"INPUT0\", \\\n",
    "                    \"shape\": [1, 16], \\\n",
    "                    \"datatype\": \"INT32\", \\\n",
    "                    \"parameters\": {}, \\\n",
    "                    \"data\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] \\\n",
    "                }, \\\n",
    "                { \\\n",
    "                    \"name\": \"INPUT1\", \\\n",
    "                    \"shape\": [1, 16], \\\n",
    "                    \"datatype\": \"INT32\", \\\n",
    "                    \"parameters\": {}, \\\n",
    "                    \"data\": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1] \\\n",
    "                } \\\n",
    "            ] \\\n",
    "        }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run prediction using Using `requests` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': 404,\n",
       "  'message': 'Field: name Error: Online prediction is unavailable for this version. Please verify that CreateVersion has completed successfully.',\n",
       "  'status': 'NOT_FOUND',\n",
       "  'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest',\n",
       "    'fieldViolations': [{'field': 'name',\n",
       "      'description': 'Online prediction is unavailable for this version. Please verify that CreateVersion has completed successfully.'}]}]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('simple.json', 'r') as s:\n",
    "    data=s.read()\n",
    "    \n",
    "PREDICT_URL = \"{}/projects/{}/models/{}/versions/{}:predict\".format(ENDPOINT, PROJECT_ID, os.getenv('MODEL_NAME'), os.getenv('VERSION_NAME'))\n",
    "HEADERS = {\n",
    "  'Content-Type': 'application/octet-stream',\n",
    "  'Authorization': 'Bearer {}'.format(os.popen('gcloud auth application-default print-access-token').read().rstrip())\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", PREDICT_URL, headers=HEADERS, data = data).content.decode()\n",
    "\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-50 model (binary data)\n",
    "\n",
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BINARY_MODEL_NAME=resnet50_netdef\n"
     ]
    }
   ],
   "source": [
    "%env BINARY_MODEL_NAME=resnet50_netdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 74.125.201.95:443...\n",
      "* Connected to us-central1-ml.googleapis.com (74.125.201.95) port 443 (#0)\n",
      "* ALPN, offering h2\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use h2\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Oct  6 06:40:00 2020 GMT\n",
      "*  expire date: Dec 29 06:40:00 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "* Using HTTP2, server supports multi-use\n",
      "* Connection state changed (HTTP/2 confirmed)\n",
      "* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n",
      "* Using Stream ID: 1 (easy handle 0x562770bb4da0)\n",
      "> POST /v1/projects/tsaikevin-1238/models/ HTTP/2\n",
      "> Host: us-central1-ml.googleapis.com\n",
      "> user-agent: curl/7.71.1\n",
      "> accept: */*\n",
      "> content-type: application/json\n",
      "> authorization: Bearer ya29.a0AfH6SMBQYut23sHkwTf6fYX3MnLEtGe4_kR3opNnm9iEgKZwCp4fWQQNe_7nHwreGhSbc_zYGm4FpUFFmEfcPUXwxmEqEDWT7RLx9C0fk06BHsK3N0qq3E_z0UdXD2lnayGcQf6VO-InrQi8jYX-bRhGeY3QPYjsIpXtyvHUg3xS\n",
      "> content-length: 27\n",
      "> \n",
      "* Connection state changed (MAX_CONCURRENT_STREAMS == 100)!\n",
      "* We are completely uploaded and fine\n",
      "< HTTP/2 200 \n",
      "< content-type: application/json; charset=UTF-8\n",
      "< vary: X-Origin\n",
      "< vary: Referer\n",
      "< vary: Origin,Accept-Encoding\n",
      "< date: Mon, 26 Oct 2020 07:26:27 GMT\n",
      "< server: ESF\n",
      "< cache-control: private\n",
      "< x-xss-protection: 0\n",
      "< x-frame-options: SAMEORIGIN\n",
      "< x-content-type-options: nosniff\n",
      "< accept-ranges: none\n",
      "< \n",
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/models/resnet50_netdef\",\n",
      "  \"regions\": [\n",
      "    \"us-central1\"\n",
      "  ],\n",
      "  \"etag\": \"VN/0SwaI5Nw=\"\n",
      "}\n",
      "* Connection #0 to host us-central1-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -v -k -H \"Content-Type: application/json\" \\\n",
    "  -d \"{'name': '\"$BINARY_MODEL_NAME\"'}\" \\\n",
    "  -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "  \"${ENDPOINT}/projects/${PROJECT_ID}/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BINARY_VERSION_NAME=v1\n"
     ]
    }
   ],
   "source": [
    "%env BINARY_VERSION_NAME=v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_binary_version = {\n",
    "  \"name\": os.getenv(\"BINARY_VERSION_NAME\"),\n",
    "  \"deployment_uri\": os.getenv(\"MODEL_BUCKET\")+\"/model_repository\",\n",
    "  \"container\": {\n",
    "    \"image\": os.getenv(\"CAIP_IMAGE\"),\n",
    "    \"args\": [\"tritonserver\",\n",
    "             \"--model-repository=$(AIP_STORAGE_URI)\"\n",
    "    ],\n",
    "    \"env\": [\n",
    "    ], \n",
    "    \"ports\": [\n",
    "      { \"containerPort\": 8000 }\n",
    "    ]\n",
    "  },\n",
    "  \"routes\": {\n",
    "    \"predict\": \"/v2/models/\"+os.getenv(\"BINARY_MODEL_NAME\")+\"/infer\",\n",
    "    \"health\": \"/v2/models/\"+os.getenv(\"BINARY_MODEL_NAME\")\n",
    "  },\n",
    "  \"machine_type\": \"n1-standard-4\",\n",
    "  \"acceleratorConfig\": {\n",
    "    \"count\":1,\n",
    "    \"type\":\"nvidia-tesla-t4\"\n",
    "  },\n",
    "  \"autoScaling\": {\n",
    "    \"minNodes\": 1\n",
    "  }\n",
    "}\n",
    "\n",
    "with open(\"triton_binary_version.json\", \"w\") as f: \n",
    "  json.dump(triton_binary_version, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 172.217.214.95:443...\n",
      "* Connected to us-central1-ml.googleapis.com (172.217.214.95) port 443 (#0)\n",
      "* ALPN, offering h2\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use h2\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Oct  6 06:40:00 2020 GMT\n",
      "*  expire date: Dec 29 06:40:00 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "* Using HTTP2, server supports multi-use\n",
      "* Connection state changed (HTTP/2 confirmed)\n",
      "* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n",
      "* Using Stream ID: 1 (easy handle 0x55d140a62570)\n",
      "> POST /v1/projects/tsaikevin-1238/models/resnet50_netdef/versions HTTP/2\n",
      "> Host: us-central1-ml.googleapis.com\n",
      "> user-agent: curl/7.71.1\n",
      "> accept: */*\n",
      "> content-type: application/json\n",
      "> authorization: Bearer ya29.a0AfH6SMBhKNlngn0exkQGAPFSelIhjJ6q-NtwqwoWd8Z3FcvdHIxEOnlsp_Ev4_cwbDFG9wq9bF4vBBKu0QABlwu3BUVhfzL38k_mgivA-dlAwIa5DD_pqnRewFoY5JvpDJEmaKxHdZyhNMMOvxuAZJd4XEnZzI86cizBzCMxrT8F\n",
      "> content-length: 521\n",
      "> \n",
      "* Connection state changed (MAX_CONCURRENT_STREAMS == 100)!\n",
      "* We are completely uploaded and fine\n",
      "< HTTP/2 200 \n",
      "< content-type: application/json; charset=UTF-8\n",
      "< vary: X-Origin\n",
      "< vary: Referer\n",
      "< vary: Origin,Accept-Encoding\n",
      "< date: Mon, 26 Oct 2020 07:26:32 GMT\n",
      "< server: ESF\n",
      "< cache-control: private\n",
      "< x-xss-protection: 0\n",
      "< x-frame-options: SAMEORIGIN\n",
      "< x-content-type-options: nosniff\n",
      "< accept-ranges: none\n",
      "< \n",
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/operations/create_resnet50_netdef_v1-1603697191889\",\n",
      "  \"metadata\": {\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.ml.v1.OperationMetadata\",\n",
      "    \"createTime\": \"2020-10-26T07:26:32Z\",\n",
      "    \"operationType\": \"CREATE_VERSION\",\n",
      "    \"modelName\": \"projects/tsaikevin-1238/models/resnet50_netdef\",\n",
      "    \"version\": {\n",
      "      \"name\": \"projects/tsaikevin-1238/models/resnet50_netdef/versions/v1\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-1238-80838/model_repository\",\n",
      "      \"createTime\": \"2020-10-26T07:26:31Z\",\n",
      "      \"autoScaling\": {\n",
      "        \"minNodes\": 1\n",
      "      },\n",
      "      \"etag\": \"w4z7ZO5sgRM=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"us-central1-docker.pkg.dev/tsaikevin-1238/caipcustom/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/resnet50_netdef/infer\",\n",
      "        \"health\": \"/v2/models/resnet50_netdef\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "* Connection #0 to host us-central1-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl --request POST -v -k -H \"Content-Type: application/json\" \\\n",
    "  -d @triton_binary_version.json \\\n",
    "  -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "  ${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Model Version status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/models/resnet50_netdef/versions/v1\",\n",
      "  \"deploymentUri\": \"gs://tsaikevin-1238-80838/model_repository\",\n",
      "  \"createTime\": \"2020-10-26T07:26:31Z\",\n",
      "  \"autoScaling\": {\n",
      "    \"minNodes\": 1\n",
      "  },\n",
      "  \"state\": \"FAILED\",\n",
      "  \"errorMessage\": \"Model server terminated: model server container terminated: exit_code: 1\\nreason: \\\"Error\\\"\\nstarted_at {\\n  seconds: 1603698840\\n}\\nfinished_at {\\n  seconds: 1603698849\\n}\\n\",\n",
      "  \"etag\": \"sq2JF8yPNkU=\",\n",
      "  \"machineType\": \"n1-standard-4\",\n",
      "  \"acceleratorConfig\": {\n",
      "    \"count\": \"1\",\n",
      "    \"type\": \"NVIDIA_TESLA_T4\"\n",
      "  },\n",
      "  \"container\": {\n",
      "    \"image\": \"us-central1-docker.pkg.dev/tsaikevin-1238/caipcustom/tritonserver:20.06-py3\",\n",
      "    \"args\": [\n",
      "      \"tritonserver\",\n",
      "      \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "    ],\n",
      "    \"ports\": [\n",
      "      {\n",
      "        \"containerPort\": 8000\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"routes\": {\n",
      "    \"predict\": \"/v2/models/resnet50_netdef/infer\",\n",
      "    \"health\": \"/v2/models/resnet50_netdef\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request GET -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions/${BINARY_VERSION_NAME}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run prediction using `curl`\n",
    "\n",
    "Recall the offset value calcuated above.  The binary case has an additional header:\n",
    "\n",
    "`Inference-Header-Content-Length: [offset]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl --request POST ${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions/${BINARY_VERSION_NAME}:predict \\\n",
    "    -k -H \"Content-Type: application/octet-stream\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    -H \"Inference-Header-Content-Length: 138\" \\\n",
    "    --data-binary @payload.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run prediction using Using `requests` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('payload.dat', 'rb') as s:\n",
    "    data=s.read()\n",
    "\n",
    "PREDICT_URL = \"{}/projects/{}/models/{}/versions/{}:predict\".format(ENDPOINT, PROJECT_ID, os.getenv('BINARY_MODEL_NAME'), os.getenv('BINARY_VERSION_NAME'))\n",
    "HEADERS = {\n",
    "  'Content-Type': 'application/octet-stream',\n",
    "  'Inference-Header-Content-Length': '138',\n",
    "  'Authorization': 'Bearer {}'.format(os.popen('gcloud auth application-default print-access-token').read().rstrip())\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", PREDICT_URL, headers=HEADERS, data = data).content.decode()\n",
    "\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"Field: name Error: The specified model version was not found.\",\n",
      "    \"status\": \"NOT_FOUND\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\n",
      "        \"fieldViolations\": [\n",
      "          {\n",
      "            \"field\": \"name\",\n",
      "            \"description\": \"The specified model version was not found.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request DELETE -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions/${BINARY_VERSION_NAME}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/operations/delete_model_resnet50_netdef-1603699560\",\n",
      "  \"metadata\": {\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.ml.v1.OperationMetadata\",\n",
      "    \"createTime\": \"2020-10-26T08:06:00Z\",\n",
      "    \"operationType\": \"DELETE_MODEL\",\n",
      "    \"modelName\": \"projects/tsaikevin-1238/models/resnet50_netdef\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request DELETE -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"Field: name Error: The specified model version was not found.\",\n",
      "    \"status\": \"NOT_FOUND\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\n",
      "        \"fieldViolations\": [\n",
      "          {\n",
      "            \"field\": \"name\",\n",
      "            \"description\": \"The specified model version was not found.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request DELETE -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/${VERSION_NAME}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/tsaikevin-1238/operations/delete_model_simple-1603699566\",\n",
      "  \"metadata\": {\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.ml.v1.OperationMetadata\",\n",
      "    \"createTime\": \"2020-10-26T08:06:06Z\",\n",
      "    \"operationType\": \"DELETE_MODEL\",\n",
      "    \"modelName\": \"projects/tsaikevin-1238/models/simple\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request DELETE -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://tsaikevin-1238-80838/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r -f $MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf model_repository triton-inference-server *.dat *.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-cpu.1-15.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-cpu.1-15:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
