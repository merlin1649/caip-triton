{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying NVIDIA Triton Inference Server in AI Platform Prediction Custom Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk through the process of deploying NVIDIA's Triton Inference Server into AI Platform Prediction Custom Container service in the Direct Model Server mode:\n",
    "\n",
    "![](img/caip_triton_container_diagram_direct.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJECT_ID=\"[enter project name]\"\n",
    "%env MODEL_BUCKET=\"gs://[enter GCS bucket name]\"\n",
    "%env ENDPOINT=\"https://alpha-ml.googleapis.com/v1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJECT_ID=tsaikevin-triton-2\n",
      "env: MODEL_BUCKET=gs://tsaikevin-triton-2-models\n",
      "env: ENDPOINT=https://alpha-ml.googleapis.com/v1\n"
     ]
    }
   ],
   "source": [
    "%env PROJECT_ID=tsaikevin-triton-2\n",
    "%env MODEL_BUCKET=gs://tsaikevin-triton-2-models\n",
    "%env ENDPOINT=https://alpha-ml.googleapis.com/v1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the NVIDIA Triton Inference Server repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'triton-inference-server'...\n",
      "remote: Enumerating objects: 46, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
      "remote: Total 22796 (delta 16), reused 22 (delta 7), pack-reused 22750\u001b[K\n",
      "Receiving objects: 100% (22796/22796), 13.11 MiB | 15.87 MiB/s, done.\n",
      "Resolving deltas: 100% (16833/16833), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/triton-inference-server.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the GCS bucket where the model artifacts will be copied to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil mb $MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage model artifacts and copy to bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R triton-inference-server/docs/examples/model_repository/* model_repository/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ mkdir -p model_repository/resnet50_netdef/1\n",
      "+ wget -O model_repository/resnet50_netdef/1/model.netdef http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/predict_net.pb\n",
      "--2020-07-31 07:53:51--  http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/predict_net.pb\n",
      "Resolving download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)... 52.216.28.44\n",
      "Connecting to download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)|52.216.28.44|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31649 (31K) [binary/octet-stream]\n",
      "Saving to: ‘model_repository/resnet50_netdef/1/model.netdef’\n",
      "\n",
      "model_repository/re 100%[===================>]  30.91K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2020-07-31 07:53:51 (1.03 MB/s) - ‘model_repository/resnet50_netdef/1/model.netdef’ saved [31649/31649]\n",
      "\n",
      "+ wget -O model_repository/resnet50_netdef/1/init_model.netdef http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/init_net.pb\n",
      "--2020-07-31 07:53:51--  http://download.caffe2.ai.s3.amazonaws.com/models/resnet50/init_net.pb\n",
      "Resolving download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)... 52.216.28.44\n",
      "Connecting to download.caffe2.ai.s3.amazonaws.com (download.caffe2.ai.s3.amazonaws.com)|52.216.28.44|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 128070759 (122M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘model_repository/resnet50_netdef/1/init_model.netdef’\n",
      "\n",
      "model_repository/re 100%[===================>] 122.14M  50.5MB/s    in 2.4s    \n",
      "\n",
      "2020-07-31 07:53:53 (50.5 MB/s) - ‘model_repository/resnet50_netdef/1/init_model.netdef’ saved [128070759/128070759]\n",
      "\n",
      "+ mkdir -p model_repository/inception_graphdef/1\n",
      "+ wget -O /tmp/inception_v3_2016_08_28_frozen.pb.tar.gz https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\n",
      "--2020-07-31 07:53:53--  https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 74.125.70.128, 74.125.201.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88668554 (85M) [application/gzip]\n",
      "Saving to: ‘/tmp/inception_v3_2016_08_28_frozen.pb.tar.gz’\n",
      "\n",
      "/tmp/inception_v3_2 100%[===================>]  84.56M  88.3MB/s    in 1.0s    \n",
      "\n",
      "2020-07-31 07:53:55 (88.3 MB/s) - ‘/tmp/inception_v3_2016_08_28_frozen.pb.tar.gz’ saved [88668554/88668554]\n",
      "\n",
      "+ cd /tmp\n",
      "+ tar xzf inception_v3_2016_08_28_frozen.pb.tar.gz\n",
      "+ mv /tmp/inception_v3_2016_08_28_frozen.pb model_repository/inception_graphdef/1/model.graphdef\n",
      "+ mkdir -p model_repository/densenet_onnx/1\n",
      "+ wget -O model_repository/densenet_onnx/1/model.onnx https://contentmamluswest001.blob.core.windows.net/content/14b2744cf8d6418c87ffddc3f3127242/9502630827244d60a1214f250e3bbca7/08aed7327d694b8dbaee2c97b8d0fcba/densenet121-1.2.onnx\n",
      "--2020-07-31 07:53:56--  https://contentmamluswest001.blob.core.windows.net/content/14b2744cf8d6418c87ffddc3f3127242/9502630827244d60a1214f250e3bbca7/08aed7327d694b8dbaee2c97b8d0fcba/densenet121-1.2.onnx\n",
      "Resolving contentmamluswest001.blob.core.windows.net (contentmamluswest001.blob.core.windows.net)... 13.88.144.240\n",
      "Connecting to contentmamluswest001.blob.core.windows.net (contentmamluswest001.blob.core.windows.net)|13.88.144.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 32719461 (31M) [application/octet-stream]\n",
      "Saving to: ‘model_repository/densenet_onnx/1/model.onnx’\n",
      "\n",
      "model_repository/de 100%[===================>]  31.20M  14.2MB/s    in 2.2s    \n",
      "\n",
      "2020-07-31 07:53:59 (14.2 MB/s) - ‘model_repository/densenet_onnx/1/model.onnx’ saved [32719461/32719461]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./triton-inference-server/docs/examples/fetch_models.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -R model_repository/ $MODEL_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://tsaikevin-triton-2-models/model_repository/densenet_onnx/\n",
      "gs://tsaikevin-triton-2-models/model_repository/inception_graphdef/\n",
      "gs://tsaikevin-triton-2-models/model_repository/resnet50_netdef/\n",
      "gs://tsaikevin-triton-2-models/model_repository/simple/\n",
      "gs://tsaikevin-triton-2-models/model_repository/simple_string/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $MODEL_BUCKET/model_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and deploy Model and Model Version\n",
    "\n",
    "In this section, we will deploy two models:\n",
    "1. Simple model with non-binary data.  KF Serving v2 protocol specifies a json format with non-binary data in the json body itself.\n",
    "2. Binary data model with ResNet-50.  Triton's implementation of binary data for KF Server v2 protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model with non-binary data\n",
    "\n",
    "#### Create Model\n",
    "\n",
    "AI Platform Prediction uses a Model/Model Version Hierarchy, where the Model is a logical grouping of Model Versions.  We will first create the Model.\n",
    "\n",
    "Because the MODEL_NAME variable will be used later to specify the predict route, and Triton will use that route to run prediction on a specific model, we must set the value of this variable to a valid name of a model.  For this section, will use the \"simple\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=simple\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME=simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 172.217.212.95:443...\n",
      "* Connected to alpha-ml.googleapis.com (172.217.212.95) port 443 (#0)\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use http/1.1\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Jul  7 08:08:59 2020 GMT\n",
      "*  expire date: Sep 29 08:08:59 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "> POST /v1/projects/tsaikevin-triton-2/models/ HTTP/1.1\n",
      "> Host: alpha-ml.googleapis.com\n",
      "> User-Agent: curl/7.71.1\n",
      "> Accept: */*\n",
      "> Content-Type: application/json\n",
      "> Authorization: Bearer ya29.c.KmrWB6CdCcBXgnGRHwGAHFCk8qQ2glNyGdQNoE108juwravsGHYUNWoZaYXVM0Xzh4rZMf7f45s0YPVZ1OJJ1piuypoIvNAGaEpWZYBf7DYkrixTTku5bb6-p2L6Em9JlBCuZA64q4w1h5k2\n",
      "> Content-Length: 18\n",
      "> \n",
      "* upload completely sent off: 18 out of 18 bytes\n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 409 Conflict\n",
      "< Vary: X-Origin\n",
      "< Vary: Referer\n",
      "< Content-Type: application/json; charset=UTF-8\n",
      "< Date: Fri, 31 Jul 2020 02:18:25 GMT\n",
      "< Server: ESF\n",
      "< Cache-Control: private\n",
      "< X-XSS-Protection: 0\n",
      "< X-Frame-Options: SAMEORIGIN\n",
      "< X-Content-Type-Options: nosniff\n",
      "< Accept-Ranges: none\n",
      "< Vary: Origin,Accept-Encoding\n",
      "< Transfer-Encoding: chunked\n",
      "< \n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 409,\n",
      "    \"message\": \"Field: model.name Error: A model with the same name already exists.\",\n",
      "    \"status\": \"ALREADY_EXISTS\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\n",
      "        \"fieldViolations\": [\n",
      "          {\n",
      "            \"field\": \"model.name\",\n",
      "            \"description\": \"A model with the same name already exists.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "* Connection #0 to host alpha-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl --request \\\n",
    "    -X POST -v -k -H \"Content-Type: application/json\" \\\n",
    "    -d \"{'name': '\"$MODEL_NAME\"'}\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Version\n",
    "\n",
    "After the Model is created, we can now create a Model Version under this Model.  Each Model Version will need a name that is unique within the Model.  In AI Platform Prediction Custom Container, a {Project}/{Model}/{ModelVersion} uniquely identifies the specific container and model artifact used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VERSION_NAME=v20\n"
     ]
    }
   ],
   "source": [
    "%env VERSION_NAME=v20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following specifications tell AI Platform how to create the Model Version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "triton_simple_version = {\n",
    "  \"name\": os.getenv(\"VERSION_NAME\"),\n",
    "  \"deployment_uri\": os.getenv(\"MODEL_BUCKET\")+\"/model_repository\",\n",
    "  \"container\": {\n",
    "    \"image\": \"gcr.io/\"+os.getenv(\"PROJECT_ID\")+\"/tritonserver:20.06-py3\",\n",
    "    \"args\": [\"tritonserver\",\n",
    "             \"--model-repository=$(AIP_STORAGE_URI)\"\n",
    "    ],\n",
    "    \"env\": [\n",
    "    ], \n",
    "    \"ports\": [\n",
    "      { \"containerPort\": 8000 }\n",
    "    ]\n",
    "  },\n",
    "  \"routes\": {\n",
    "    \"predict\": \"/v2/models/\"+os.getenv(\"MODEL_NAME\")+\"/infer\",\n",
    "    \"health\": \"/v2/models/\"+os.getenv(\"MODEL_NAME\")\n",
    "  },\n",
    "  \"machine_type\": \"n1-standard-4\",\n",
    "  \"acceleratorConfig\": {\n",
    "    \"count\":1,\n",
    "    \"type\":\"nvidia-tesla-t4\"\n",
    "  }\n",
    "}\n",
    "\n",
    "with open(\"triton_simple_version.json\", \"w\") as f: \n",
    "  json.dump(triton_simple_version, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'v20',\n",
       " 'deployment_uri': 'gs://tsaikevin-triton-2-models/model_repository',\n",
       " 'container': {'image': 'gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3',\n",
       "  'args': ['tritonserver', '--model-repository=$(AIP_STORAGE_URI)'],\n",
       "  'env': [],\n",
       "  'ports': [{'containerPort': 8000}]},\n",
       " 'routes': {'predict': '/v2/models/simple/infer',\n",
       "  'health': '/v2/models/simple'},\n",
       " 'machine_type': 'n1-standard-4',\n",
       " 'acceleratorConfig': {'count': 1, 'type': 'nvidia-tesla-t4'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_simple_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 172.217.214.95:443...\n",
      "* Connected to alpha-ml.googleapis.com (172.217.214.95) port 443 (#0)\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use http/1.1\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Jul  7 08:08:59 2020 GMT\n",
      "*  expire date: Sep 29 08:08:59 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "> POST /v1/projects/tsaikevin-triton-2/models/simple/versions HTTP/1.1\n",
      "> Host: alpha-ml.googleapis.com\n",
      "> User-Agent: curl/7.71.1\n",
      "> Accept: */*\n",
      "> Content-Type: application/json\n",
      "> Authorization: Bearer ya29.c.KmrWB71c8JRq8fdVpE71ytk-6nQyAIyQNm9FrNySX6wzWvVaSI9AOfYzGBjWrVd90wn_LbEYSFm62Ke3XVGmb-ToOH2OLrl9egKTjuj1av0HqLJBd9NzTinoC2zy-KIh1yCH_PZSX3TuWYCC\n",
      "> Content-Length: 450\n",
      "> \n",
      "* upload completely sent off: 450 out of 450 bytes\n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Type: application/json; charset=UTF-8\n",
      "< Vary: X-Origin\n",
      "< Vary: Referer\n",
      "< Date: Fri, 31 Jul 2020 07:54:31 GMT\n",
      "< Server: ESF\n",
      "< Cache-Control: private\n",
      "< X-XSS-Protection: 0\n",
      "< X-Frame-Options: SAMEORIGIN\n",
      "< X-Content-Type-Options: nosniff\n",
      "< Accept-Ranges: none\n",
      "< Vary: Origin,Accept-Encoding\n",
      "< Transfer-Encoding: chunked\n",
      "< \n",
      "{\n",
      "  \"name\": \"projects/tsaikevin-triton-2/operations/create_simple_v20-1596182069639\",\n",
      "  \"metadata\": {\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.ml.v1.OperationMetadata\",\n",
      "    \"createTime\": \"2020-07-31T07:54:31Z\",\n",
      "    \"operationType\": \"CREATE_VERSION\",\n",
      "    \"modelName\": \"projects/tsaikevin-triton-2/models/simple\",\n",
      "    \"version\": {\n",
      "      \"name\": \"projects/tsaikevin-triton-2/models/simple/versions/v20\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-triton-2-models/model_repository\",\n",
      "      \"createTime\": \"2020-07-31T07:54:29Z\",\n",
      "      \"etag\": \"j1eQBipoNk4=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/simple/infer\",\n",
      "        \"health\": \"/v2/models/simple\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "* Connection #0 to host alpha-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl --request \\\n",
    "    POST -v -k -H \"Content-Type: application/json\" \\\n",
    "    -d @triton_simple_version.json \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of Model Version creation\n",
    "\n",
    "Creating a Model Version may take several minutes.  You can check on the status of this specfic Model Version with the following, and a successful deployment will show:\n",
    "\n",
    "`\"state\": \"READY\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/tsaikevin-triton-2/models/simple/versions/v20\",\n",
      "  \"deploymentUri\": \"gs://tsaikevin-triton-2-models/model_repository\",\n",
      "  \"createTime\": \"2020-07-31T07:54:29Z\",\n",
      "  \"state\": \"CREATING\",\n",
      "  \"etag\": \"Be1xEHxSY7M=\",\n",
      "  \"machineType\": \"n1-standard-4\",\n",
      "  \"acceleratorConfig\": {\n",
      "    \"count\": \"1\",\n",
      "    \"type\": \"NVIDIA_TESLA_T4\"\n",
      "  },\n",
      "  \"container\": {\n",
      "    \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "    \"args\": [\n",
      "      \"tritonserver\",\n",
      "      \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "    ],\n",
      "    \"ports\": [\n",
      "      {\n",
      "        \"containerPort\": 8000\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"routes\": {\n",
      "    \"predict\": \"/v2/models/simple/infer\",\n",
      "    \"health\": \"/v2/models/simple\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request GET -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/${VERSION_NAME}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To list all Model Versions and their states in this Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"versions\": [\n",
      "    {\n",
      "      \"name\": \"projects/tsaikevin-triton-2/models/simple/versions/v15\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-triton-2-models\",\n",
      "      \"createTime\": \"2020-07-30T10:25:03Z\",\n",
      "      \"state\": \"FAILED\",\n",
      "      \"errorMessage\": \"model server container terminated: exit_code: 1\\nreason: \\\"Error\\\"\\nstarted_at {\\n  seconds: 1596106476\\n}\\nfinished_at {\\n  seconds: 1596106485\\n}\\n\",\n",
      "      \"etag\": \"7ExBP8Ff1Y8=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/simple/infer\",\n",
      "        \"health\": \"/v2/models/simple\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"projects/tsaikevin-triton-2/models/simple/versions/v16\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-triton-2-models/model_repository\",\n",
      "      \"createTime\": \"2020-07-30T18:24:00Z\",\n",
      "      \"state\": \"FAILED\",\n",
      "      \"errorMessage\": \"model server container terminated: exit_code: 1\\nreason: \\\"Error\\\"\\nstarted_at {\\n  seconds: 1596135121\\n}\\nfinished_at {\\n  seconds: 1596135135\\n}\\n\",\n",
      "      \"etag\": \"5MQClXSM07w=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/simple/infer\",\n",
      "        \"health\": \"/v2/models/simple\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"projects/tsaikevin-triton-2/models/simple/versions/v17\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-triton-2-models/model_repository\",\n",
      "      \"createTime\": \"2020-07-30T19:00:02Z\",\n",
      "      \"state\": \"FAILED\",\n",
      "      \"errorMessage\": \"model server container terminated: exit_code: 1\\nreason: \\\"Error\\\"\\nstarted_at {\\n  seconds: 1596137300\\n}\\nfinished_at {\\n  seconds: 1596137313\\n}\\n\",\n",
      "      \"etag\": \"tcOqWCaEc50=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/simple/infer\",\n",
      "        \"health\": \"/v2/models/simple\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"projects/tsaikevin-triton-2/models/simple/versions/v18\",\n",
      "      \"isDefault\": true,\n",
      "      \"deploymentUri\": \"gs://tsaikevin-triton-2-models/model_repository\",\n",
      "      \"createTime\": \"2020-07-30T19:27:12Z\",\n",
      "      \"lastUseTime\": \"2020-07-31T02:31:27Z\",\n",
      "      \"state\": \"READY\",\n",
      "      \"etag\": \"2NLkH+4gw7w=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/simple/infer\",\n",
      "        \"health\": \"/v2/models/simple\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request GET -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Prediction\n",
    "\n",
    "The \"simple\" model takes two tensors with shape [1,16] and does a couple of basic arithmetic operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"0\",\"model_name\":\"simple\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"OUTPUT0\",\"datatype\":\"INT32\",\"shape\":[1,16],\"data\":[-1,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]},{\"name\":\"OUTPUT1\",\"datatype\":\"INT32\",\"shape\":[1,16],\"data\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}]}"
     ]
    }
   ],
   "source": [
    "!curl -X POST ${ENDPOINT}/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/${VERSION_NAME}:predict \\\n",
    "    -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    -d '{ \\\n",
    "            \"id\": \"0\", \\\n",
    "            \"inputs\": [ \\\n",
    "                { \\\n",
    "                    \"name\": \"INPUT0\", \\\n",
    "                    \"shape\": [1, 16], \\\n",
    "                    \"datatype\": \"INT32\", \\\n",
    "                    \"parameters\": {}, \\\n",
    "                    \"data\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] \\\n",
    "                }, \\\n",
    "                { \\\n",
    "                    \"name\": \"INPUT1\", \\\n",
    "                    \"shape\": [1, 16], \\\n",
    "                    \"datatype\": \"INT32\", \\\n",
    "                    \"parameters\": {}, \\\n",
    "                    \"data\": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1] \\\n",
    "                } \\\n",
    "            ] \\\n",
    "        }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-50 with binary data\n",
    "\n",
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BINARY_MODEL_NAME=resnet50_netdef\n"
     ]
    }
   ],
   "source": [
    "%env BINARY_MODEL_NAME=resnet50_netdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 74.125.69.95:443...\n",
      "* Connected to alpha-ml.googleapis.com (74.125.69.95) port 443 (#0)\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use http/1.1\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Jul  7 08:08:59 2020 GMT\n",
      "*  expire date: Sep 29 08:08:59 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "> POST /v1/projects/tsaikevin-triton-2/models/ HTTP/1.1\n",
      "> Host: alpha-ml.googleapis.com\n",
      "> User-Agent: curl/7.71.1\n",
      "> Accept: */*\n",
      "> Content-Type: application/json\n",
      "> Authorization: Bearer ya29.c.KmrWB8psGSBGJaok8nTpPWFi2Yo0Kif4w_D63otUng05keRYMJ9rZCSS-l6u-kMpzT2hNU3mLe-hre10iw7KqAYZe2okDHPwunckiPs7N4f9XLTB5Sci5j3wtDwCX8pvQ-cXeFUo6fGMHi4-\n",
      "> Content-Length: 27\n",
      "> \n",
      "* upload completely sent off: 27 out of 27 bytes\n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Type: application/json; charset=UTF-8\n",
      "< Vary: X-Origin\n",
      "< Vary: Referer\n",
      "< Date: Fri, 31 Jul 2020 01:54:24 GMT\n",
      "< Server: ESF\n",
      "< Cache-Control: private\n",
      "< X-XSS-Protection: 0\n",
      "< X-Frame-Options: SAMEORIGIN\n",
      "< X-Content-Type-Options: nosniff\n",
      "< Accept-Ranges: none\n",
      "< Vary: Origin,Accept-Encoding\n",
      "< Transfer-Encoding: chunked\n",
      "< \n",
      "{\n",
      "  \"name\": \"projects/tsaikevin-triton-2/models/resnet50_netdef\",\n",
      "  \"regions\": [\n",
      "    \"us-central1\"\n",
      "  ],\n",
      "  \"etag\": \"5bjZ72iqpQ8=\"\n",
      "}\n",
      "* Connection #0 to host alpha-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -v -k -H \"Content-Type: application/json\" \\\n",
    "  -d \"{'name': '\"$BINARY_MODEL_NAME\"'}\" \\\n",
    "  -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "  \"${ENDPOINT}/projects/${PROJECT_ID}/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BINARY_VERSION_NAME=v2\n"
     ]
    }
   ],
   "source": [
    "%env BINARY_VERSION_NAME=v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_binary_version = {\n",
    "  \"name\": os.getenv(\"BINARY_VERSION_NAME\"),\n",
    "  \"deployment_uri\": os.getenv(\"MODEL_BUCKET\")+\"/model_repository\",\n",
    "  \"container\": {\n",
    "    \"image\": \"gcr.io/\"+os.getenv(\"PROJECT_ID\")+\"/tritonserver:20.06-py3\",\n",
    "    \"args\": [\"tritonserver\",\n",
    "             \"--model-repository=$(AIP_STORAGE_URI)\"\n",
    "    ],\n",
    "    \"env\": [\n",
    "    ], \n",
    "    \"ports\": [\n",
    "      { \"containerPort\": 8000 }\n",
    "    ]\n",
    "  },\n",
    "  \"routes\": {\n",
    "    \"predict\": \"/v2/models/\"+os.getenv(\"BINARY_MODEL_NAME\")+\"/infer\",\n",
    "    \"health\": \"/v2/models/\"+os.getenv(\"BINARY_MODEL_NAME\")\n",
    "  },\n",
    "  \"machine_type\": \"n1-standard-4\",\n",
    "  \"acceleratorConfig\": {\n",
    "    \"count\":1,\n",
    "    \"type\":\"nvidia-tesla-t4\"\n",
    "  }\n",
    "}\n",
    "\n",
    "with open(\"triton_binary_version.json\", \"w\") as f: \n",
    "  json.dump(triton_binary_version, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 172.217.214.95:443...\n",
      "* Connected to alpha-ml.googleapis.com (172.217.214.95) port 443 (#0)\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*   CAfile: /opt/conda/ssl/cacert.pem\n",
      "  CApath: none\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use http/1.1\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=upload.video.google.com\n",
      "*  start date: Jul  7 08:08:59 2020 GMT\n",
      "*  expire date: Sep 29 08:08:59 2020 GMT\n",
      "*  issuer: C=US; O=Google Trust Services; CN=GTS CA 1O1\n",
      "*  SSL certificate verify ok.\n",
      "> POST /v1/projects/tsaikevin-triton-2/models/resnet50_netdef/versions HTTP/1.1\n",
      "> Host: alpha-ml.googleapis.com\n",
      "> User-Agent: curl/7.71.1\n",
      "> Accept: */*\n",
      "> Content-Type: application/json\n",
      "> Authorization: Bearer ya29.c.KmrWB71c8JRq8fdVpE71ytk-6nQyAIyQNm9FrNySX6wzWvVaSI9AOfYzGBjWrVd90wn_LbEYSFm62Ke3XVGmb-ToOH2OLrl9egKTjuj1av0HqLJBd9NzTinoC2zy-KIh1yCH_PZSX3TuWYCC\n",
      "> Content-Length: 467\n",
      "> \n",
      "* upload completely sent off: 467 out of 467 bytes\n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Type: application/json; charset=UTF-8\n",
      "< Vary: X-Origin\n",
      "< Vary: Referer\n",
      "< Date: Fri, 31 Jul 2020 07:54:59 GMT\n",
      "< Server: ESF\n",
      "< Cache-Control: private\n",
      "< X-XSS-Protection: 0\n",
      "< X-Frame-Options: SAMEORIGIN\n",
      "< X-Content-Type-Options: nosniff\n",
      "< Accept-Ranges: none\n",
      "< Vary: Origin,Accept-Encoding\n",
      "< Transfer-Encoding: chunked\n",
      "< \n",
      "{\n",
      "  \"name\": \"projects/tsaikevin-triton-2/operations/create_resnet50_netdef_v2-1596182097820\",\n",
      "  \"metadata\": {\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.ml.v1.OperationMetadata\",\n",
      "    \"createTime\": \"2020-07-31T07:54:58Z\",\n",
      "    \"operationType\": \"CREATE_VERSION\",\n",
      "    \"modelName\": \"projects/tsaikevin-triton-2/models/resnet50_netdef\",\n",
      "    \"version\": {\n",
      "      \"name\": \"projects/tsaikevin-triton-2/models/resnet50_netdef/versions/v2\",\n",
      "      \"deploymentUri\": \"gs://tsaikevin-triton-2-models/model_repository\",\n",
      "      \"createTime\": \"2020-07-31T07:54:57Z\",\n",
      "      \"etag\": \"ogB16fPlExo=\",\n",
      "      \"machineType\": \"n1-standard-4\",\n",
      "      \"acceleratorConfig\": {\n",
      "        \"count\": \"1\",\n",
      "        \"type\": \"NVIDIA_TESLA_T4\"\n",
      "      },\n",
      "      \"container\": {\n",
      "        \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "        \"args\": [\n",
      "          \"tritonserver\",\n",
      "          \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "        ],\n",
      "        \"ports\": [\n",
      "          {\n",
      "            \"containerPort\": 8000\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"routes\": {\n",
      "        \"predict\": \"/v2/models/resnet50_netdef/infer\",\n",
      "        \"health\": \"/v2/models/resnet50_netdef\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "* Connection #0 to host alpha-ml.googleapis.com left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -v -k -H \"Content-Type: application/json\" \\\n",
    "  -d @triton_binary_version.json \\\n",
    "  -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "  ${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Model Version status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/tsaikevin-triton-2/models/resnet50_netdef/versions/v2\",\n",
      "  \"deploymentUri\": \"gs://tsaikevin-triton-2-models/model_repository\",\n",
      "  \"createTime\": \"2020-07-31T07:54:57Z\",\n",
      "  \"state\": \"CREATING\",\n",
      "  \"etag\": \"3PLPMvxvNd0=\",\n",
      "  \"machineType\": \"n1-standard-4\",\n",
      "  \"acceleratorConfig\": {\n",
      "    \"count\": \"1\",\n",
      "    \"type\": \"NVIDIA_TESLA_T4\"\n",
      "  },\n",
      "  \"container\": {\n",
      "    \"image\": \"gcr.io/tsaikevin-triton-2/tritonserver:20.06-py3\",\n",
      "    \"args\": [\n",
      "      \"tritonserver\",\n",
      "      \"--model-repository=$(AIP_STORAGE_URI)\"\n",
      "    ],\n",
      "    \"ports\": [\n",
      "      {\n",
      "        \"containerPort\": 8000\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"routes\": {\n",
      "    \"predict\": \"/v2/models/resnet50_netdef/infer\",\n",
      "    \"health\": \"/v2/models/resnet50_netdef\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request GET -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    \"${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions/${BINARY_VERSION_NAME}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Binary Request Payload\n",
    "\n",
    "Triton's implementation of KF Serving v2 protocol for binary data appends the binary data after the json body.  Triton requires an additional header for offset:\n",
    "\n",
    "`Inference-Header-Content-Length: [offset]`\n",
    "\n",
    "We have provided a script that will automatically resize the image to the proper size for ResNet-50 [224, 224, 3] and calculate the proper offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geventhttpclient\n",
      "  Downloading geventhttpclient-1.4.4-cp37-cp37m-manylinux2010_x86_64.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: gevent>=0.13 in /opt/conda/lib/python3.7/site-packages (from geventhttpclient) (20.6.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from geventhttpclient) (2020.6.20)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from geventhttpclient) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (49.2.0.post20200712)\n",
      "Requirement already satisfied: zope.interface in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (5.1.0)\n",
      "Requirement already satisfied: zope.event in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (4.4)\n",
      "Requirement already satisfied: greenlet>=0.4.16; platform_python_implementation == \"CPython\" in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient) (0.4.16)\n",
      "Installing collected packages: geventhttpclient\n",
      "Successfully installed geventhttpclient-1.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install geventhttpclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command takes an image file and outputs the necessary data structure for Triton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n",
      "Add Header: Inference-Header-Content-Length: 138\n"
     ]
    }
   ],
   "source": [
    "!python3 get_request_body_simple.py -m image -f triton-inference-server/qa/images/mug.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 400,\n",
      "    \"message\": \"{\\\"error\\\":\\\"unexpected size for input 'gpu_0/data', expecting 599327 bytes for model 'resnet50_netdef'\\\"}\",\n",
      "    \"status\": \"INVALID_ARGUMENT\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl --request POST ${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions/${BINARY_VERSION_NAME}:predict \\\n",
    "    -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    -H \"Inference-Header-Content-Length: 138\" \\\n",
    "    -d @payload.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 400,\n",
      "    \"message\": \"{\\\"error\\\":\\\"failed to parse the request JSON buffer: The document root must not be followed by other values. at 138\\\"}\",\n",
      "    \"status\": \"INVALID_ARGUMENT\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST ${ENDPOINT}/projects/${PROJECT_ID}/models/${BINARY_MODEL_NAME}/versions/${BINARY_VERSION_NAME}:predict \\\n",
    "    -k -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    -d @payload.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triton-inference-server/qa/images:\n",
      "total 1092\n",
      "-rw-r--r-- 1 jupyter jupyter    7999 Jul 30 09:42 car.jpg\n",
      "-rw-r--r-- 1 jupyter jupyter 1005970 Jul 30 09:42 mug.jpg\n",
      "-rw-r--r-- 1 jupyter jupyter   99689 Jul 30 09:42 vulture.jpeg\n"
     ]
    }
   ],
   "source": [
    "!ls -lR triton-inference-server/qa/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\tv2/simple_setup/car.jpg\n",
      "M\tv2/simple_setup/get_request_body_simple.py\n",
      "D\tv2/simple_setup/mug.jpg\n",
      "D\tv2/simple_setup/simple.dat\n",
      "D\tv2/simple_setup/simple.json\n",
      "D\tv2/simple_setup/vulture.jpeg\n",
      "Your branch is up-to-date with 'origin/master'.\n"
     ]
    }
   ],
   "source": [
    "!git checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Unable to create '/home/jupyter/caip-triton/.git/index.lock': File exists.\n",
      "\n",
      "Another git process seems to be running in this repository, e.g.\n",
      "an editor opened by 'git commit'. Please make sure all processes\n",
      "are terminated then try again. If it still fails, a git process\n",
      "may have crashed in this repository earlier:\n",
      "remove the file manually to continue.\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-cpu.1-15.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-cpu.1-15:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
